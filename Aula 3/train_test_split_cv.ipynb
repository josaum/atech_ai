{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como Fazer \"Train Test Split\" Corretamente\n",
    "\n",
    "#### Ao construir modelos de aprendizado de máquina, uma etapa crucial é dividir seus dados em conjuntos de treino, teste e, às vezes, validação. Esta divisão ajuda a garantir que seu modelo tenha um bom desempenho não apenas nos dados que ele já viu, mas também em dados novos e não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A Importância do Conjunto de Treino, Teste e Validação\n",
    "#### 1.1 Conjunto de Treino\n",
    "\n",
    "Objetivo: Treinar o modelo. \n",
    "\n",
    "O conjunto de treino é usado para treinar o modelo, ou seja, ajustar os parâmetros do modelo aos dados. Este é o conjunto em que o modelo \"aprende\".\n",
    "\n",
    "#### 1.2 Conjunto de Teste\n",
    "\n",
    "Objetivo: Avaliar o modelo.\n",
    "\n",
    "O conjunto de teste é usado para avaliar o desempenho do modelo. Ele fornece uma estimativa imparcial do desempenho do modelo na prática. Se você usar o conjunto de treino para avaliar o desempenho do modelo, poderá superestimar o desempenho do modelo, pois o modelo já viu todos os dados de treinamento.\n",
    "\n",
    "#### 1.3 Conjunto de Validação\n",
    "\n",
    "Objetivo: Ajustar hiperparâmetros e selecionar o melhor modelo.\n",
    "\n",
    "O conjunto de validação é usado para ajustar hiperparâmetros e escolher o melhor modelo entre vários candidatos. Ajuda a evitar o \"overfitting\" nos dados de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *O fluxo comum é: Treino --> Validação (opcional) --> Teste*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train Test Split Aleatório vs Temporalmente Estruturado\n",
    "#### 2.1 Aleatório\n",
    "Este é o método mais comum. Os dados são divididos aleatoriamente em conjuntos de treino e teste. É útil quando as observações são independentes entre si.\n",
    "\n",
    "Exemplo em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "X: (1000, 2) y: (1000,)\n",
      "Train dataset size:\n",
      "X: (800, 2) y: (800,)\n",
      "Test dataset size:\n",
      "X: (200, 2) y: (200,)\n",
      "% Train: 0.8\n",
      "% Test: 0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=1, n_samples=1000, random_state=42)\n",
    "\n",
    "\n",
    "# test_size = 0.2 --> significa que 20% dos dados serão usados para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Total dataset size:\")\n",
    "print(\"X:\", X.shape, \"y:\", y.shape)\n",
    "print(\"Train dataset size:\")\n",
    "print(\"X:\", X_train.shape, \"y:\", y_train.shape)\n",
    "print(\"Test dataset size:\")\n",
    "print(\"X:\", X_test.shape, \"y:\", y_test.shape)\n",
    "\n",
    "print(\"% Train:\", X_train.shape[0]/X.shape[0])\n",
    "print(\"% Test:\", X_test.shape[0]/X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Aleatório com classificação estratificada\n",
    "Este método é recomendado quando estamos lidando com conjuntos de dados onde a distribuição das classes é desbalanceada. Ele garante que a proporção de cada classe no conjunto de treino e teste seja a mesma que no conjunto de dados original.\n",
    "\n",
    "Exemplo em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporção da classe 1 no dataset original: 0.006\n",
      "Proporção da classe 1 no conjunto de treino: 0.0075\n",
      "Proporção da classe 1 no conjunto de teste: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Criando um dataset de exemplo desbalanceado\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=1, n_samples=1000, weights=[0.999, 0.001], random_state=42)\n",
    "\n",
    "# Divisão estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificando as proporções\n",
    "print(\"Proporção da classe 1 no dataset original:\", sum(y) / len(y))\n",
    "print(\"Proporção da classe 1 no conjunto de treino:\", sum(y_train) / len(y_train))\n",
    "print(\"Proporção da classe 1 no conjunto de teste:\", sum(y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporção da classe 1 no dataset original: 0.006\n",
      "Proporção da classe 1 no conjunto de treino: 0.00625\n",
      "Proporção da classe 1 no conjunto de teste: 0.005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Criando um dataset de exemplo desbalanceado\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=1, n_samples=1000, weights=[0.999, 0.001], random_state=42)\n",
    "\n",
    "# Divisão estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Verificando as proporções\n",
    "print(\"Proporção da classe 1 no dataset original:\", sum(y) / len(y))\n",
    "print(\"Proporção da classe 1 no conjunto de treino:\", sum(y_train) / len(y_train))\n",
    "print(\"Proporção da classe 1 no conjunto de teste:\", sum(y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Com estrutura temporal\n",
    "Quando o problema possui estrutura temporal (ou seja, os dados são coletados ao longo do tempo), é importante dividir os dados em conjuntos de treino e teste de acordo com a estrutura temporal. Isso significa que os dados mais antigos são usados para treinar o modelo e os dados mais recentes são usados para testar o modelo. Isso é importante para prevenir o \"data leakage\" (vazamento de dados), que é quando as informações do futuro são usadas para prever o passado.\n",
    "\n",
    "Exemplo em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: (366, 2)\n",
      "Data de corte: 2020-10-19 00:00:00\n",
      "Train dataset size: (292, 2)\n",
      "Test dataset size: (74, 2)\n",
      "% Train: 0.7978142076502732\n",
      "% Test: 0.20218579234972678\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "date_rng = pd.date_range(start='2020-01-01', end='2020-12-31', freq='D')\n",
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "df['data'] = np.random.randint(0,100,size=(len(date_rng)))\n",
    "\n",
    "# Dividindo os dados\n",
    "train_size = int(len(df) * 0.8)\n",
    "\n",
    "# qual foi a data de  corte?\n",
    "data_corte = df['date'][train_size]\n",
    "\n",
    "# qual é o index da data de corte?\n",
    "index_corte = df[df['date'] == data_corte].index[0]\n",
    "\n",
    "train, test = df[0:index_corte], df[index_corte:len(df)]\n",
    "\n",
    "print(\"Total dataset size:\", df.shape)\n",
    "print(\"Data de corte:\", df['date'][train_size])\n",
    "print(\"Train dataset size:\", train.shape)\n",
    "print(\"Test dataset size:\", test.shape)\n",
    "print(\"% Train:\", train.shape[0]/df.shape[0])\n",
    "print(\"% Test:\", test.shape[0]/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cross Validation\n",
    "Cross Validation (CV) é uma técnica que divide o conjunto de dados em \"k\" subconjuntos. O modelo é treinado em \"k-1\" desses subconjuntos e testado no subconjunto restante. Este processo é repetido \"k\" vezes, com cada subconjunto usado exatamente uma vez como conjunto de teste.\n",
    "\n",
    "O método mais comum de CV é o k-fold CV.\n",
    "\n",
    "Exemplo em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores do Cross Validation: [0.995 0.995 0.995 0.995 0.99 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print(f'Scores do Cross Validation: {scores}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Leakage: vazamento de informação através do pré-processamento\n",
    "O vazamento de dados ocorre quando informações do conjunto de dados de teste são usadas para treinar o modelo. Isso pode acontecer inadvertidamente durante o pré-processamento. Um exemplo clássico de vazamento é a normalização ou padronização dos dados.\n",
    "\n",
    "#### 4.1 Normalização\n",
    "Se normalizarmos (ou padronizarmos) todo o conjunto de dados antes de dividir em treino e teste, estamos usando informações do conjunto de teste para definir a escala dos dados de treino. Isso pode levar a resultados otimistas e enganosos.\n",
    "\n",
    "Exemplo em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultados com a normalização incorreta ----\n",
      "Acurácia: 0.695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69        85\n",
      "           1       0.81      0.62      0.70       115\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.71      0.71      0.69       200\n",
      "weighted avg       0.72      0.69      0.70       200\n",
      "\n",
      "\n",
      "---- Resultados com a normalização correta ----\n",
      "Acurácia: 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        91\n",
      "           1       0.55      1.00      0.71       109\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.27      0.50      0.35       200\n",
      "weighted avg       0.30      0.55      0.38       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josaum/opt/anaconda3/envs/atech-ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/josaum/opt/anaconda3/envs/atech-ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/josaum/opt/anaconda3/envs/atech-ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Criando um dataset com distribuições diferentes para treino e teste\n",
    "X_train = np.random.randn(800, 1)\n",
    "X_test = np.random.normal(5, 1, size=(200, 1))\n",
    "y_train = (X_train > X_train.mean()).astype(int).ravel()\n",
    "y_test = (X_test > X_test.mean()).astype(int).ravel()\n",
    "\n",
    "# Concatenando treino e teste\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# Aplicando o StandardScaler de forma incorreta\n",
    "scaler_bad = StandardScaler()\n",
    "X_scaled_bad = scaler_bad.fit_transform(X_combined)\n",
    "\n",
    "X_train_bad, X_test_bad, y_train_bad, y_test_bad = train_test_split(X_scaled_bad, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# A forma correta\n",
    "scaler_correct = StandardScaler()\n",
    "X_train_correct = scaler_correct.fit_transform(X_train)\n",
    "X_test_correct = scaler_correct.transform(X_test)\n",
    "\n",
    "# Modelo treinado com a normalização incorreta\n",
    "model_bad = LogisticRegression(random_state=42)\n",
    "model_bad.fit(X_train_bad, y_train_bad)\n",
    "y_pred_bad = model_bad.predict(X_test_bad)\n",
    "\n",
    "# Modelo treinado com a normalização correta\n",
    "model_correct = LogisticRegression(random_state=42)\n",
    "model_correct.fit(X_train_correct, y_train)\n",
    "y_pred_correct = model_correct.predict(X_test_correct)\n",
    "\n",
    "# Métricas para a normalização incorreta\n",
    "accuracy_bad = accuracy_score(y_test_bad, y_pred_bad)\n",
    "report_bad = classification_report(y_test_bad, y_pred_bad)\n",
    "\n",
    "# Métricas para a normalização correta\n",
    "accuracy_correct = accuracy_score(y_test, y_pred_correct)\n",
    "report_correct = classification_report(y_test, y_pred_correct)\n",
    "\n",
    "print(\"---- Resultados com a normalização incorreta ----\")\n",
    "print(\"Acurácia:\", accuracy_bad)\n",
    "print(report_bad)\n",
    "\n",
    "print(\"\\n---- Resultados com a normalização correta ----\")\n",
    "print(\"Acurácia:\", accuracy_correct)\n",
    "print(report_correct)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atech-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

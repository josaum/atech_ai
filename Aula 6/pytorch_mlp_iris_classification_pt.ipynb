{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6e10dd",
   "metadata": {},
   "source": [
    "# Construindo uma MLP com PyTorch: Classificação do Conjunto de Dados Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e7090",
   "metadata": {},
   "source": [
    "\n",
    "Nesta parte final do notebook, vamos aplicar o que aprendemos para construir uma rede neural MLP (Perceptron Multicamadas) \n",
    "usando PyTorch e treiná-la no conjunto de dados Iris para classificar as espécies de iris com base em suas características.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aff05e",
   "metadata": {},
   "source": [
    "\n",
    "## Índice\n",
    "\n",
    "1. [Preprocessamento dos Dados](#preprocessamento-dos-dados)\n",
    "2. [Construindo uma Rede Neural MLP com PyTorch](#construindo-uma-rede-neural-mlp-com-pytorch)\n",
    "   - [Definindo a Rede Neural](#definindo-a-rede-neural)\n",
    "   - [Função de Perda e Otimizador](#funcao-de-perda-e-otimizador)\n",
    "   - [Treinamento da Rede](#treinamento-da-rede)\n",
    "   - [Avaliação do Modelo](#avaliacao-do-modelo)\n",
    "3. [Conclusão e Próximos Passos](#conclusao-e-proximos-passos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac9af2",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessamento dos Dados\n",
    "\n",
    "Antes de alimentar o conjunto de dados Iris para nossa rede neural, precisamos preprocessá-lo. O preprocessamento de dados \n",
    "é um passo crucial na construção de modelos de aprendizado de máquina e inclui tarefas como a normalização dos dados \n",
    "(ou seja, colocar todos os recursos na mesma escala), a divisão dos dados em conjuntos de treinamento e teste, e a \n",
    "conversão dos rótulos em um formato que pode ser facilmente usado para treinar a rede.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4e93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5247fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "# carregar iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Carregar dados\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19e0ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990a2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar os recursos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4e78c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.50652052,  1.24920112, -1.56757623, -1.3154443 ],\n",
       "        [-0.17367395,  3.09077525, -1.2833891 , -1.05217993],\n",
       "        [ 1.03800476,  0.09821729,  0.36489628,  0.26414192],\n",
       "        [-1.26418478,  0.78880759, -1.22655167, -1.3154443 ],\n",
       "        [-1.74885626,  0.32841405, -1.39706395, -1.3154443 ]]),\n",
       " array([0, 0, 1, 0, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e2d6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Converter arrays numpy em tensores PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long) # Os rótulos são de tipo long\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Criar DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07281f8",
   "metadata": {},
   "source": [
    "\n",
    "## Construindo uma Rede Neural MLP com PyTorch\n",
    "\n",
    "### Definindo a Rede Neural\n",
    "Agora que nossos dados estão prontos, podemos definir nossa rede neural. Vamos construir uma rede MLP simples com uma \n",
    "camada oculta. PyTorch oferece a classe `nn.Module`, que é a classe base para todos os modelos de rede neural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84fcf66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP(\n",
      "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # input_\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Número de recursos de entrada (4 características), número de classes (3 tipos de iris)\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = SimpleMLP(input_size, hidden_size, num_classes)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adb0fce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1279, 0.1254, 0.2883], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536dd36",
   "metadata": {},
   "source": [
    "\n",
    "### Função de Perda e Otimizador\n",
    "\n",
    "Depois de definir a rede neural, precisamos definir uma função de perda e escolher um método de otimização. A função de perda, \n",
    "também conhecida como critério, mede o desempenho do modelo em termos de quão bem ele prevê os rótulos verdadeiros. O otimizador \n",
    "ajusta os parâmetros do modelo para minimizar a função de perda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b3e40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir a função de perda e o otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # lr = learning rate (taxa de aprendizado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d04c8",
   "metadata": {},
   "source": [
    "\n",
    "### Treinamento da Rede\n",
    "\n",
    "Com tudo pronto, agora podemos treinar nossa rede. O treinamento de uma rede neural com PyTorch envolve passar pelos dados \n",
    "em épocas, onde em cada época, passamos por cada lote de dados do conjunto de treinamento. Para cada lote, executamos o \n",
    "processo de forward pass (calculando a saída do modelo e a perda), backpropagation (calculando os gradientes dos parâmetros) \n",
    "e otimização (atualizando os parâmetros com o otimizador).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1978e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir o número de épocas\n",
    "num_epochs = 50\n",
    "\n",
    "# Armazenar as perdas a cada época\n",
    "loss_values = []\n",
    "\n",
    "# Treinamento da rede\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):  \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 30 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    loss_values.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886ac5d",
   "metadata": {},
   "source": [
    "\n",
    "### Avaliação do Modelo\n",
    "\n",
    "Depois de treinar o modelo, queremos avaliar seu desempenho no conjunto de dados de teste. Isso é feito passando as \n",
    "características de teste através do modelo e comparando as saídas previstas com os rótulos verdadeiros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70a5db75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo no conjunto de treinamento: 27.5%\n",
      "Acurácia do modelo no conjunto de teste: 36.666666666666664%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Avaliar o modelo\n",
    "model.eval()  # Modo de avaliação\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Acurácia do modelo no conjunto de treinamento: {100 * correct / total}%')\n",
    "\n",
    "# Testar o modelo com o conjunto de teste\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = y_test_tensor.size(0)\n",
    "    correct = (predicted == y_test_tensor).sum().item()\n",
    "\n",
    "    print(f'Acurácia do modelo no conjunto de teste: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c02e8703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.4615, -0.3760,  0.3352,  0.1857],\n",
       "         [ 0.2408, -0.1824,  0.3896, -0.3109],\n",
       "         [ 0.4700, -0.0204,  0.0446, -0.3956],\n",
       "         [-0.3670, -0.0942,  0.2002,  0.0256],\n",
       "         [-0.2217, -0.0156,  0.4536, -0.4472],\n",
       "         [-0.0838, -0.4924,  0.0745,  0.0247],\n",
       "         [ 0.2375, -0.4780,  0.3855, -0.2136],\n",
       "         [-0.3364, -0.2123, -0.1836,  0.4425],\n",
       "         [ 0.3200,  0.4839,  0.1815, -0.4457],\n",
       "         [ 0.4992, -0.0481, -0.0751, -0.4213]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2045,  0.4381,  0.3455,  0.0183, -0.0587,  0.2297, -0.1840,  0.3434,\n",
       "         -0.3068,  0.2191], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0918,  0.1891, -0.0334,  0.1853, -0.1538,  0.2245, -0.1660,  0.0854,\n",
       "          -0.2037,  0.0687],\n",
       "         [-0.1507, -0.2738, -0.2944, -0.2543,  0.2120, -0.2743, -0.2186, -0.0053,\n",
       "           0.0276, -0.0507],\n",
       "         [ 0.0887, -0.0363,  0.0649,  0.0668, -0.0282, -0.0424, -0.1369,  0.1828,\n",
       "           0.2477,  0.2171]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1245, 0.1448, 0.1815], requires_grad=True)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be8c57",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusão e Próximos Passos\n",
    "\n",
    "Neste notebook, abordamos os conceitos básicos do PyTorch e do deep learning e aplicamos esse conhecimento na construção \n",
    "e treinamento de uma rede neural MLP para classificar o conjunto de dados Iris. O PyTorch oferece uma ampla gama de \n",
    "funcionalidades que facilitam a construção e o treinamento de modelos de deep learning, mas isso é apenas a ponta do iceberg. \n",
    "Há muitos outros conceitos e técnicas em deep learning e PyTorch para explorar, incluindo diferentes tipos de redes neurais \n",
    "(como CNNs para processamento de imagem e RNNs para sequências de tempo), técnicas de regularização como dropout, e métodos \n",
    "de otimização avançados. Esperamos que este notebook sirva como um ponto de partida sólido para sua jornada no deep learning!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atech-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Diferença entre Métricas e Losses\n",
    "\n",
    "- **Loss (Função de Perda)**: É uma função que mede o quão bem o modelo está se saindo em relação aos dados de treinamento. Durante o treinamento, o objetivo é minimizar essa função. A função de perda é usada pelo algoritmo de otimização para atualizar os parâmetros do modelo.\n",
    "\n",
    "- **Métrica**: É uma função que mede a qualidade do modelo em relação a uma tarefa específica (por exemplo, classificação, regressão). Ao contrário das funções de perda, as métricas são usadas para interpretar e avaliar o desempenho do modelo, mas não são usadas diretamente no processo de treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "### Métricas e Funções de Perda para Regressão:\n",
    "\n",
    "#### 1. Erro Quadrático Médio (MSE - Mean Squared Error)\n",
    "\n",
    "- **Definição Matemática**:\n",
    "\n",
    "\\[\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "\\]\n",
    "\n",
    "- **Premissas**:\n",
    "  - Assume que os erros são distribuídos normalmente.\n",
    "  \n",
    "- **Pontos Fortes**: \n",
    "  - Penaliza outliers fortemente devido ao quadrado.\n",
    "  \n",
    "- **Pontos Fracos**: \n",
    "  - Pode ser sensível a outliers.\n",
    "\n",
    "- **Código Python**:\n",
    "\n",
    "```python\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "```\n",
    "\n",
    "#### 2. Erro Absoluto Médio (MAE - Mean Absolute Error)\n",
    "\n",
    "- **Definição Matemática**:\n",
    "\n",
    "\\[\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "\\]\n",
    "\n",
    "- **Premissas**:\n",
    "  - Não assume uma distribuição específica dos erros.\n",
    "  \n",
    "- **Pontos Fortes**: \n",
    "  - Menos sensível a outliers do que o MSE.\n",
    "  \n",
    "- **Pontos Fracos**: \n",
    "  - Não penaliza erros grandes tanto quanto o MSE.\n",
    "\n",
    "- **Código Python**:\n",
    "\n",
    "```python\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "```\n",
    "\n",
    "#### 3. Raiz do Erro Quadrático Médio (RMSE - Root Mean Squared Error)\n",
    "\n",
    "- **Definição Matemática**:\n",
    "\n",
    "\\[\n",
    "\\text{RMSE} = \\sqrt{\\text{MSE}}\n",
    "\\]\n",
    "\n",
    "- **Premissas**:\n",
    "  - Assume que os erros são distribuídos normalmente.\n",
    "  \n",
    "- **Pontos Fortes**: \n",
    "  - É uma das métricas mais usadas, e sua escala é a mesma que a variável de resposta.\n",
    "  \n",
    "- **Pontos Fracos**: \n",
    "  - Sensível a outliers.\n",
    "\n",
    "- **Código Python**:\n",
    "\n",
    "```python\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "```\n",
    "\n",
    "#### 4. Erro Percentual Absoluto Médio (MAPE - Mean Absolute Percentage Error)\n",
    "\n",
    "- **Definição Matemática**:\n",
    "\n",
    "\\[\n",
    "\\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right|\n",
    "\\]\n",
    "\n",
    "- **Premissas**:\n",
    "  - Os verdadeiros valores não devem ser zero, pois divide por \\(y_i\\).\n",
    "  \n",
    "- **Pontos Fortes**: \n",
    "  - Escala independente, fácil interpretação em termos percentuais.\n",
    "  \n",
    "- **Pontos Fracos**: \n",
    "  - Infinito ou indefinido se o verdadeiro valor for zero para qualquer observação. Pode fornecer erros muito grandes se os valores verdadeiros estiverem próximos de zero.\n",
    "\n",
    "- **Código Python**:\n",
    "\n",
    "```python\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "```\n",
    "\n",
    "#### 5. R-Squared (Coeficiente de Determinação)\n",
    "\n",
    "- **Definição Matemática**:\n",
    "\n",
    "\\[\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "\\]\n",
    "\n",
    "- **Premissas**:\n",
    "  - Assume que os erros são distribuídos normalmente.\n",
    "  \n",
    "- **Pontos Fortes**: \n",
    "  - Mede a proporção da variância total explicada pelo modelo. Valores mais próximos de 1 indicam um bom ajuste.\n",
    "  \n",
    "- **Pontos Fracos**: \n",
    "  - Pode ser um indicador enganoso do ajuste do modelo se o modelo não for ajustado ao intercepto. Além disso, sempre aumenta à medida que mais variáveis são adicionadas, independentemente de sua utilidade.\n",
    "\n",
    "- **Código Python**:\n",
    "\n",
    "```python\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred)**2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "```\n",
    "\n",
    "#### 6. Quantile Loss\n",
    "\n",
    "- **Definição Matemática**:\n",
    "\n",
    "\\[\n",
    "QL_{\\tau}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} \\left[ \\tau \\cdot \\max(y_i - \\hat{y}_i, 0) + (1-\\tau) \\cdot \\max(\\hat{y}_i - y_i, 0) \\right]\n",
    "\\]\n",
    "\n",
    "- **Premissas**:\n",
    "  - Não assume uma distribuição específica para os erros.\n",
    "  \n",
    "- **Pontos Fortes**: \n",
    "  - Penaliza erros acima ou abaixo do quantil de interesse de forma diferenciada, permitindo modelar a incerteza de maneira mais flexível.\n",
    "  \n",
    "- **Pontos Fracos**: \n",
    "  - Para cada quantil desejado, é necessário treinar um modelo diferente.\n",
    "\n",
    "- **Código Python**:\n",
    "\n",
    "```python\n",
    "def quantile_loss(y_true, y_pred, tau=0.5):\n",
    "    return np.mean(np.where(y_true >= y_pred, tau * (y_true - y_pred), (1 - tau) * (y_pred - y_true)))\n",
    "```\n",
    "\n",
    "#### 7. MASE (Mean Absolute Scaled Error)\n",
    "\n",
    "- **Definição Matemática**:\n",
    "\n",
    "\\[\n",
    "\\text{MASE} = \\frac{\\text{MAE}}{\\frac{1}{n-1} \\sum_{i=2}^{n} |y_i - y_{i-1}|}\n",
    "\\]\n",
    "\n",
    "- **Premissas**:\n",
    "  - Assume que o método de referência é a\n",
    "\n",
    " previsão \"naive\", que apenas considera o último valor observado.\n",
    "  \n",
    "- **Pontos Fortes**: \n",
    "  - Escala independente, fácil interpretação. Útil quando se deseja comparar o desempenho do modelo em relação a um método simples de referência.\n",
    "  \n",
    "- **Pontos Fracos**: \n",
    "  - O denominador, baseado na previsão \"naive\", pode não ser adequado para todos os casos, especialmente para séries temporais não estacionárias.\n",
    "\n",
    "- **Código Python**:\n",
    "\n",
    "```python\n",
    "def mase(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    naive_forecast = y_true[:-1]\n",
    "    y_t_minus_one = y_true[1:]\n",
    "    mae_naive = np.mean(np.abs(y_t_minus_one - naive_forecast))\n",
    "    mae_model = mae(y_true[1:], y_pred[1:])\n",
    "    return mae_model / mae_naive\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atech-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
